{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cPCytQpQ2GX"
      },
      "source": [
        "# Disease Prediction Model\n",
        "\n",
        "This notebook contains the original code for defining and training the prediction model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cym6CCF-7Slx"
      },
      "outputs": [],
      "source": [
        "#Getting all necessary imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import sklearn\n",
        "import joblib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DZSlM1Cz8C21"
      },
      "outputs": [],
      "source": [
        "#Reading Training and Testing files\n",
        "\n",
        "df_train = pd.read_csv(\"Training.csv\")\n",
        "df_train2 = pd.read_csv(\"Training.csv\")\n",
        "df_test = pd.read_csv(\"Testing.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sb9y2YT2V9vg"
      },
      "outputs": [],
      "source": [
        "#Identifying all possible diseases from Training file (and checking length)\n",
        "\n",
        "train_label_copy = df_train[\"prognosis\"]\n",
        "\n",
        "train_labels = []\n",
        "\n",
        "for val in train_label_copy:\n",
        "  count = 0\n",
        "  for val2 in train_labels:\n",
        "    if (val == val2):\n",
        "      count += 1\n",
        "  if count == 0:\n",
        "    train_labels.append(val)\n",
        "\n",
        "#print(len(train_labels))\n",
        "#print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PCV0vKyTpCFJ"
      },
      "outputs": [],
      "source": [
        "#Defining function that manually encodes every prognosis with a corresponding integer\n",
        "#(for one hot encoding later)\n",
        "\n",
        "def prognosis_encode(arr):\n",
        "  encoded_column = []\n",
        "\n",
        "  for val1 in range(len(arr)):\n",
        "    for val2 in range(len(train_labels)):\n",
        "      if (arr[val1] == train_labels[val2]):\n",
        "        encoded_column.append(val2)\n",
        "\n",
        "  return encoded_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZq95tyRmXN"
      },
      "source": [
        "For the input data to be compatible with the neural network, any string data must be one_hot_encoded. This is a method of binary encoding any categorical data. However, the tensorflow function that executes this process only takes integer input data.\n",
        "\n",
        "As a result, the function defined above manually encodes the categorical data to be represented by ints from 0 to 40."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C5CiWy0t0QVG"
      },
      "outputs": [],
      "source": [
        "df_train2 = df_train[\"prognosis\"] #Defining dataframe of just prognosis column\n",
        "int_encoded_col = prognosis_encode(df_train2) #Storing manually encoded column to new variable\n",
        "df_train2 = np.column_stack((df_train2, int_encoded_col)) #Adding manually encoded column to new dataframe\n",
        "df_train2 = np.delete(df_train2, 0, 1) #Deleting old String based prognosis column\n",
        "y_train = to_categorical(df_train2, num_classes=41)\n",
        "#Using tensorflow's one hot encoding function on integer encoded column (more compatible with neural network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DVgAvwX3YgZ9"
      },
      "outputs": [],
      "source": [
        "#Dropping unneccesary columns from X_train and X_test\n",
        "\n",
        "X_train = df_train.drop([\"prognosis\", \"encoder\"], axis='columns')\n",
        "X_test = df_test.drop([\"prognosis\", \"encoder\"], axis='columns')\n",
        "\n",
        "#Converting all input data to float32 (decimals)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "#Converting X_train and X_test to numpy objects\n",
        "\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iDusZOQZMwyS"
      },
      "outputs": [],
      "source": [
        "#Creating Neural Network (defining architecture)\n",
        "\n",
        "model = Sequential() #Definiing neural network type (feedforward)\n",
        "model.add(Dense(64, input_dim=132, activation='relu')) #Input layer (64 parameters, 132 input features)\n",
        "model.add(Dense(32, activation=\"relu\")) #Hidding layer\n",
        "model.add(Dense(41, activation='softmax')) #Output layer (41 possible diseases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zfwLpTO3RBw9"
      },
      "outputs": [],
      "source": [
        "#Compiling model (given previously defined architecture)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWhtVSj5RDlW",
        "outputId": "e247a119-4185-4d72-e487-c181d91bc7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "154/154 [==============================] - 2s 5ms/step - loss: 2.4073 - accuracy: 0.6451\n",
            "Epoch 2/5\n",
            "154/154 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "154/154 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1d8a1120750>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fitting model to input data\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['trained_disease_model.pkl']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filename = \"trained_disease_model.pkl\"\n",
        "joblib.dump(model, filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
